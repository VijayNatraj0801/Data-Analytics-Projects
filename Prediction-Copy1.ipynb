{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [20/Jun/2022 15:17:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [20/Jun/2022 15:17:31] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "chunk:   3%|█▋                                                               | 3/118 [00:00<00:04, 28.25it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in test.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Jun/2022 15:18:10] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
      "chunk:   3%|█▋                                                               | 3/117 [00:00<00:04, 25.56it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in test.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Jun/2022 15:18:46] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import requests, uuid\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from flask import Flask, flash, request, redirect, url_for, render_template\n",
    "\n",
    "from werkzeug.utils import secure_filename\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import moviepy.editor as mp\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.secret_key = \"secret key\"\n",
    "\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024\n",
    "\n",
    "ALLOWED_EXTENSIONS = set(['png','jpg'])\n",
    "encoder=joblib.load('Encoder.joblib')\n",
    "scaler=joblib.load('Scaler.joblib')\n",
    "face_model = load_model('face_model.h5')\n",
    "class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "def pred_and_plot(model, filename, class_names):\n",
    "\n",
    "    # Import the target image and preprocess it\n",
    "    img = load_and_prep_image(filename)\n",
    "\n",
    "    # Make a prediction\n",
    "    pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "    # Get the predicted class\n",
    "    pred_class = class_names[int(tf.round(pred)[0][0])]\n",
    "\n",
    "    return pred_class\n",
    "\n",
    "def load_and_prep_image(filename, img_shape=48):\n",
    "\n",
    "    # Read in target file (an image)\n",
    "    img = tf.io.read_file(filename)\n",
    "\n",
    "    # Decode the read file into a tensor & ensure 3 colour channels\n",
    "    # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
    "    img = tf.image.decode_image(img, channels=1)\n",
    "\n",
    "    # Resize the image (to the same size our model was trained on)\n",
    "    img = tf.image.resize(img, size = [img_shape, img_shape])\n",
    "\n",
    "    # Rescale the image (get all values between 0 and 1)\n",
    "    img = img/255.\n",
    "    return img\n",
    "\n",
    "def noise(data):\n",
    "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data, speed_factor = 1.25):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "def lower_speed(data, speed_factor = 0.75):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "#sample_rate = 22050\n",
    "\n",
    "def extract_features(data):\n",
    "\n",
    "    result = np.array([])\n",
    "\n",
    "    #mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=42) #42 mfcc so we get frames of ~60 ms\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=58)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    result = np.array(mfccs_processed)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=3, offset=0.5, res_type='kaiser_fast')\n",
    "\n",
    "    #without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "\n",
    "    #noised\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    #stretched\n",
    "    stretch_data = stretch(data)\n",
    "    res3 = extract_features(stretch_data)\n",
    "    result = np.vstack((result, res3))\n",
    "\n",
    "    #shifted\n",
    "    shift_data = shift(data)\n",
    "    res4 = extract_features(shift_data)\n",
    "    result = np.vstack((result, res4))\n",
    "\n",
    "    #pitched\n",
    "    pitch_data = pitch(data, sample_rate)\n",
    "    res5 = extract_features(pitch_data)\n",
    "    result = np.vstack((result, res5))\n",
    "\n",
    "    #speed up\n",
    "    higher_speed_data = higher_speed(data)\n",
    "    res6 = extract_features(higher_speed_data)\n",
    "    result = np.vstack((result, res6))\n",
    "\n",
    "    #speed down\n",
    "    lower_speed_data = higher_speed(data)\n",
    "    res7 = extract_features(lower_speed_data)\n",
    "    result = np.vstack((result, res7))\n",
    "\n",
    "    return result\n",
    "\n",
    "def predict(path):\n",
    "    features = get_features(path)\n",
    "    check = []\n",
    "    for elem in features:\n",
    "        check.append(elem)\n",
    "    total_model = load_model('model123.h5')\n",
    "    ans = total_model.predict(np.expand_dims(scaler.transform(features),2))\n",
    "    ans = ans.mean(axis=0)\n",
    "    return ans\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def upload_image():\n",
    "    if 'file' not in request.files:\n",
    "        flash('No file part')\n",
    "        return redirect(request.url)\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        flash('No image selected for uploading')\n",
    "        return redirect(request.url)\n",
    "    if file and True:\n",
    "        filename = secure_filename(file.filename)\n",
    "#         m = pred_and_plot(face_model, file, class_names)\n",
    "        cap = cv2.VideoCapture(filename)\n",
    "        l = []\n",
    "        # Check if camera opened successfully\n",
    "        if (cap.isOpened()== False):\n",
    "            print(\"Error opening video file\")\n",
    "\n",
    "        # Read until video is completed\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if(True):\n",
    "                if ret == True:\n",
    "                    grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    grey = cv2.resize(grey, (48, 48))\n",
    "                    l.append(face_model.predict(tf.expand_dims(grey, axis=0)))\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "        ans_1 = np.array(pd.DataFrame(np.squeeze(np.array(l))).mean(axis=0))\n",
    "        ans_1 = np. delete(ans_1, 4)\n",
    "        my_clip = mp.VideoFileClip(filename)\n",
    "        my_clip.audio.write_audiofile(\"test.wav\")\n",
    "        ans_2 = predict('C:\\\\Users\\\\vjlaa\\\\Desktop\\\\Multimodal\\\\test.wav')\n",
    "        ans = ans_1 + ans_2\n",
    "        m = class_names[ans.argmax()]\n",
    "        flash('The predicted emotion is: ' + m)\n",
    "        return render_template('index.html')\n",
    "    else:\n",
    "        flash('Allowed image types are - png, jpg, jpeg, gif')\n",
    "        return redirect(request.url)\n",
    "\n",
    "\n",
    "@app.route('/display/<filename>')\n",
    "def display_image(filename):\n",
    "    print('display_image filename: ' + filename)\n",
    "    return redirect(url_for('static', filename='uploads/' + filename), code=301)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   # app.run(debug=True)\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 8000, app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589263a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc442379",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bda5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0c2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
