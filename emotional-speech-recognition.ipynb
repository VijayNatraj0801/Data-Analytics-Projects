{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054365,
     "end_time": "2022-04-25T19:16:55.872526",
     "exception": false,
     "start_time": "2022-04-25T19:16:55.818161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>Emotional Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7e18703a-b1a4-43af-9d09-13261b337ca3",
    "_uuid": "a399e368-7306-4d35-992c-77760316a39e",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:55.981070Z",
     "iopub.status.busy": "2022-04-25T19:16:55.980541Z",
     "iopub.status.idle": "2022-04-25T19:16:57.957033Z",
     "shell.execute_reply": "2022-04-25T19:16:57.956385Z",
     "shell.execute_reply.started": "2022-04-25T18:20:26.823931Z"
    },
    "papermill": {
     "duration": 2.03446,
     "end_time": "2022-04-25T19:16:57.957195",
     "exception": false,
     "start_time": "2022-04-25T19:16:55.922735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music.\n",
    "# It can be used to extract the data from the audio files we will see it later\n",
    "import librosa \n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050025,
     "end_time": "2022-04-25T19:16:58.091403",
     "exception": false,
     "start_time": "2022-04-25T19:16:58.041378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "** Since the feature extraction require a huge amount of time, before we start, in the codelines below, specify if there are already dataframes available and if so the path of those ones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:58.195108Z",
     "iopub.status.busy": "2022-04-25T19:16:58.194289Z",
     "iopub.status.idle": "2022-04-25T19:16:58.196321Z",
     "shell.execute_reply": "2022-04-25T19:16:58.196704Z",
     "shell.execute_reply.started": "2022-04-25T18:20:26.834512Z"
    },
    "papermill": {
     "duration": 0.056213,
     "end_time": "2022-04-25T19:16:58.196815",
     "exception": false,
     "start_time": "2022-04-25T19:16:58.140602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_FRAMES = False\n",
    "fem_path = 'features/Female_features.csv'\n",
    "mal_path = 'features/Male_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "7072a6fc-9273-4fb3-89c6-7e1e7246a484",
    "_uuid": "142fee18-07b4-49df-a886-4ee6a3c2e3d7",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:58.399157Z",
     "iopub.status.busy": "2022-04-25T19:16:58.398485Z",
     "iopub.status.idle": "2022-04-25T19:16:58.401416Z",
     "shell.execute_reply": "2022-04-25T19:16:58.400970Z",
     "shell.execute_reply.started": "2022-04-25T18:20:26.849120Z"
    },
    "papermill": {
     "duration": 0.05608,
     "end_time": "2022-04-25T19:16:58.401517",
     "exception": false,
     "start_time": "2022-04-25T19:16:58.345437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TESS = \"TESS Toronto emotional speech set data/\"\n",
    "RAV = \"RAVD/\"\n",
    "SAVEE = \"ALL/\"\n",
    "CREMA = \"AudioWAV/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "a78f27ff-88d3-4220-bef3-ce16e2472153",
    "_uuid": "1d64dee5-8878-49e3-b6b8-13fa0f528588",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:58.513643Z",
     "iopub.status.busy": "2022-04-25T19:16:58.513118Z",
     "iopub.status.idle": "2022-04-25T19:16:58.599983Z",
     "shell.execute_reply": "2022-04-25T19:16:58.599144Z",
     "shell.execute_reply.started": "2022-04-25T18:20:26.858858Z"
    },
    "papermill": {
     "duration": 0.146875,
     "end_time": "2022-04-25T19:16:58.600081",
     "exception": false,
     "start_time": "2022-04-25T19:16:58.453206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>ALL/JK_sa01.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>ALL/JK_sa15.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ALL/DC_n13.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise</td>\n",
       "      <td>ALL/DC_su09.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ALL/DC_n07.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels             path\n",
       "0       sad  ALL/JK_sa01.wav\n",
       "1       sad  ALL/JK_sa15.wav\n",
       "2   neutral   ALL/DC_n13.wav\n",
       "3  surprise  ALL/DC_su09.wav\n",
       "4   neutral   ALL/DC_n07.wav"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data location for SAVEE\n",
    "dir_list = os.listdir(SAVEE)\n",
    "\n",
    "# parse the filename to get the emotions\n",
    "emotion=[]\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('angry')\n",
    "    elif i[-8:-6]=='_d':\n",
    "        emotion.append('disgust')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('fear')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('happy')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('neutral')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('sad')\n",
    "    elif i[-8:-6]=='su':\n",
    "        emotion.append('surprise')\n",
    "    else:\n",
    "        emotion.append('unknown') \n",
    "    path.append(SAVEE + i)\n",
    "\n",
    "# Now check out the label count distribution \n",
    "SAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "SAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "print('SAVEE dataset')\n",
    "SAVEE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7f8faee9-ebb5-4147-a013-39eb98c725c4",
    "_uuid": "0e76fe25-cb0e-4816-b5b0-331fdce27070",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:58.711665Z",
     "iopub.status.busy": "2022-04-25T19:16:58.710059Z",
     "iopub.status.idle": "2022-04-25T19:16:59.043535Z",
     "shell.execute_reply": "2022-04-25T19:16:59.043072Z",
     "shell.execute_reply.started": "2022-04-25T18:20:27.068233Z"
    },
    "papermill": {
     "duration": 0.392685,
     "end_time": "2022-04-25T19:16:59.043641",
     "exception": false,
     "start_time": "2022-04-25T19:16:58.650956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the data location for TESS\n",
    "path = []\n",
    "emotion = []\n",
    "dir_list = os.listdir(TESS)\n",
    "dir_list.remove('.DS_Store')\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(TESS + i)   \n",
    "    for f in fname:\n",
    "        if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "            emotion.append('angry')\n",
    "        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "            emotion.append('disgust')\n",
    "        elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "            emotion.append('fear')\n",
    "        elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "            emotion.append('happy')\n",
    "        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "            emotion.append('neutral')                                \n",
    "        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "            emotion.append('surprise')               \n",
    "        elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "            emotion.append('sad')\n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(TESS + i + \"/\" + f)\n",
    "\n",
    "TESS_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "#TESS_df['source'] = 'TESS'\n",
    "TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "print('TESS dataset')\n",
    "TESS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_df.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "221fd993-f8d0-4099-a9db-e82873b95a76",
    "_uuid": "d34c2cbb-a405-4f5f-b408-7036c94c5358",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:59.158432Z",
     "iopub.status.busy": "2022-04-25T19:16:59.157826Z",
     "iopub.status.idle": "2022-04-25T19:16:59.558066Z",
     "shell.execute_reply": "2022-04-25T19:16:59.559020Z",
     "shell.execute_reply.started": "2022-04-25T18:20:27.896342Z"
    },
    "papermill": {
     "duration": 0.464338,
     "end_time": "2022-04-25T19:16:59.559212",
     "exception": false,
     "start_time": "2022-04-25T19:16:59.094874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing datas from RAVDESS\n",
    "dir_list = os.listdir(RAV)\n",
    "\n",
    "males = []\n",
    "females = [] \n",
    "dir_list.remove('.DS_Store')  \n",
    "dir_list.remove('audio_speech_actors_01-24') \n",
    "for actor in dir_list:\n",
    "    files = os.listdir(RAV + actor)\n",
    "        \n",
    "    for file in files: \n",
    "        part = file.split('.')[0]\n",
    "        part = part.split(\"-\")           \n",
    "        temp = int(part[6])        \n",
    "                \n",
    "        if part[2] == '01':\n",
    "            emotion = 'neutral'\n",
    "        elif part[2] == '02':\n",
    "            emotion = 'calm'\n",
    "        elif part[2] == '03':\n",
    "            emotion = 'happy'\n",
    "        elif part[2] == '04':\n",
    "            emotion = 'sad'\n",
    "        elif part[2] == '05':\n",
    "            emotion = 'angry'\n",
    "        elif part[2] == '06':\n",
    "            emotion = 'fear'\n",
    "        elif part[2] == '07':\n",
    "            emotion = 'disgust'\n",
    "        elif part[2] == '08':\n",
    "            emotion = 'surprise'\n",
    "        else:\n",
    "            emotion = 'unknown'\n",
    "            \n",
    "        if temp%2 == 0:\n",
    "            path = (RAV + actor + '/' + file)\n",
    "            #emotion = 'female_'+emotion\n",
    "            females.append([emotion, path]) \n",
    "        else:\n",
    "            path = (RAV + actor + '/' + file)\n",
    "             #emotion = 'male_'+emotion\n",
    "            males.append([emotion, path])   \n",
    "    \n",
    "   \n",
    "RavFemales_df = pd.DataFrame(females)\n",
    "RavFemales_df.columns = ['labels', 'path']\n",
    "\n",
    "RavMales_df = pd.DataFrame(males)\n",
    "RavMales_df.columns = ['labels', 'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RavFemales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "031a3f2e-8331-47db-9853-fd6c8e7c3598",
    "_uuid": "933a3449-7f09-40cd-b984-df2198f4c291",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:59.704578Z",
     "iopub.status.busy": "2022-04-25T19:16:59.703630Z",
     "iopub.status.idle": "2022-04-25T19:16:59.708215Z",
     "shell.execute_reply": "2022-04-25T19:16:59.708684Z",
     "shell.execute_reply.started": "2022-04-25T18:20:28.316743Z"
    },
    "papermill": {
     "duration": 0.082489,
     "end_time": "2022-04-25T19:16:59.708803",
     "exception": false,
     "start_time": "2022-04-25T19:16:59.626314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RavMales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e8294225-2e2b-4377-92df-b06c13413a07",
    "_uuid": "5e4028e1-2f7c-4afc-8e9a-b817e2b0e0fc",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:16:59.847260Z",
     "iopub.status.busy": "2022-04-25T19:16:59.846691Z",
     "iopub.status.idle": "2022-04-25T19:17:00.207584Z",
     "shell.execute_reply": "2022-04-25T19:17:00.207094Z",
     "shell.execute_reply.started": "2022-04-25T18:20:28.334755Z"
    },
    "papermill": {
     "duration": 0.426485,
     "end_time": "2022-04-25T19:17:00.207696",
     "exception": false,
     "start_time": "2022-04-25T19:16:59.781211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = os.listdir(CREMA)\n",
    "\n",
    "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
    "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
    "males = []\n",
    "females = []\n",
    "\n",
    "for file in files: \n",
    "    part = file.split('_')   \n",
    "    \n",
    "    if part[2] == 'SAD':\n",
    "        emotion = 'sad'\n",
    "    elif part[2] == 'ANG':\n",
    "        emotion = 'angry'\n",
    "    elif part[2] == 'DIS':\n",
    "        emotion = 'disgust'\n",
    "    elif part[2] == 'FEA':\n",
    "        emotion = 'fear'\n",
    "    elif part[2] == 'HAP':\n",
    "        emotion = 'happy'\n",
    "    elif part[2] == 'NEU':\n",
    "        emotion = 'neutral'  \n",
    "    else:\n",
    "        emotion = 'unknown'\n",
    "        \n",
    "    if int(part[0]) in female:\n",
    "        path = (CREMA + '/' + file)\n",
    "        #emotion = 'female_'+emotion\n",
    "        females.append([emotion, path]) \n",
    "    else:\n",
    "        path = (CREMA + '/' + file)\n",
    "        #emotion = 'male_'+emotion\n",
    "        males.append([emotion, path])   \n",
    "    \n",
    "CremaFemales_df = pd.DataFrame(females)\n",
    "CremaFemales_df.columns = ['labels', 'path']\n",
    "\n",
    "CremaMales_df = pd.DataFrame(males)\n",
    "CremaMales_df.columns = ['labels', 'path']\n",
    "    \n",
    "print('CREMA datasets')\n",
    "CremaFemales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b196cb88-d2a2-40a5-8b8e-842803891f2b",
    "_uuid": "4c4832b0-5fc3-4ea5-aac7-bae8daacd67d",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:00.321480Z",
     "iopub.status.busy": "2022-04-25T19:17:00.320653Z",
     "iopub.status.idle": "2022-04-25T19:17:00.324802Z",
     "shell.execute_reply": "2022-04-25T19:17:00.324253Z",
     "shell.execute_reply.started": "2022-04-25T18:20:28.739005Z"
    },
    "papermill": {
     "duration": 0.063333,
     "end_time": "2022-04-25T19:17:00.324891",
     "exception": false,
     "start_time": "2022-04-25T19:17:00.261558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CremaMales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['labels','path'])\n",
    "final_df = final_df.append(TESS_df)\n",
    "final_df = final_df.append(RavMales_df)\n",
    "final_df = final_df.append(RavFemales_df)\n",
    "final_df = final_df.append(SAVEE_df)\n",
    "final_df = final_df.append(CremaMales_df)\n",
    "final_df.to_csv(\"final_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c939896-00d4-4e4b-a0b3-6d6c1cf539d9",
    "_uuid": "7421547a-5a2f-4222-bf01-2a07cf1de863",
    "papermill": {
     "duration": 0.052967,
     "end_time": "2022-04-25T19:17:00.902816",
     "exception": false,
     "start_time": "2022-04-25T19:17:00.849849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> Data Visualization\n",
    "\n",
    "First, we will plot the number of emotions (of wich above there are the proportions).\n",
    "Then using Librosa there will be some waveplots related to each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e0a4556-54dc-4380-9dd9-e26f0ae827bb",
    "_uuid": "1371d315-b165-4330-b4c9-3d2729a3b982",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:01.025631Z",
     "iopub.status.busy": "2022-04-25T19:17:01.024996Z",
     "iopub.status.idle": "2022-04-25T19:17:01.319275Z",
     "shell.execute_reply": "2022-04-25T19:17:01.318800Z",
     "shell.execute_reply.started": "2022-04-25T18:20:29.461262Z"
    },
    "papermill": {
     "duration": 0.360245,
     "end_time": "2022-04-25T19:17:01.319426",
     "exception": false,
     "start_time": "2022-04-25T19:17:00.959181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "order = ['angry','calm','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "fig = plt.figure(figsize=(17, 5))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "plt.title('Count of Females Emotions', size=16)\n",
    "sns.countplot(Females.labels, order = order)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "fig.add_subplot(122)\n",
    "plt.title('Count of Males Emotions', size=16)\n",
    "sns.countplot(Males.labels, order = order)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f48d589-0add-4bb7-a8fb-f9f4a12e3c52",
    "_uuid": "7ec88691-2fb9-4c91-8b9a-11756aefe497",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:01.528788Z",
     "iopub.status.busy": "2022-04-25T19:17:01.527934Z",
     "iopub.status.idle": "2022-04-25T19:17:01.532365Z",
     "shell.execute_reply": "2022-04-25T19:17:01.531558Z",
     "shell.execute_reply.started": "2022-04-25T18:20:29.836243Z"
    },
    "papermill": {
     "duration": 0.133693,
     "end_time": "2022-04-25T19:17:01.532499",
     "exception": false,
     "start_time": "2022-04-25T19:17:01.398806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f'Waveplot for audio with {e} emotion', size=15)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a4a58f6d-3303-4793-b896-81fcd808596f",
    "_uuid": "1b6d7b8c-74c0-4853-b8d4-a6e7dce7576c",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:01.716897Z",
     "iopub.status.busy": "2022-04-25T19:17:01.715939Z",
     "iopub.status.idle": "2022-04-25T19:17:02.762539Z",
     "shell.execute_reply": "2022-04-25T19:17:02.762955Z",
     "shell.execute_reply.started": "2022-04-25T18:20:29.844418Z"
    },
    "papermill": {
     "duration": 1.140894,
     "end_time": "2022-04-25T19:17:02.763084",
     "exception": false,
     "start_time": "2022-04-25T19:17:01.622190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion='Angry'\n",
    "path = 'RAVD/Actor_01/03-01-05-01-01-01-01.wav'\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f97d6a01-87fa-49d7-be49-c74640b7bc2b",
    "_uuid": "34b0c3f7-6787-44c5-80bd-4c207ca8b536",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:02.896946Z",
     "iopub.status.busy": "2022-04-25T19:17:02.896427Z",
     "iopub.status.idle": "2022-04-25T19:17:03.221007Z",
     "shell.execute_reply": "2022-04-25T19:17:03.221433Z",
     "shell.execute_reply.started": "2022-04-25T18:20:31.461952Z"
    },
    "papermill": {
     "duration": 0.394086,
     "end_time": "2022-04-25T19:17:03.221566",
     "exception": false,
     "start_time": "2022-04-25T19:17:02.827480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion='Very Angry' \n",
    "path = 'RAVD/Actor_01/03-01-05-02-01-01-01.wav'\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6860263-c1df-4fd2-b0fc-77e385798849",
    "_uuid": "139edccd-bd19-4ed8-9c61-157f411e5381",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:03.373337Z",
     "iopub.status.busy": "2022-04-25T19:17:03.372789Z",
     "iopub.status.idle": "2022-04-25T19:17:03.749747Z",
     "shell.execute_reply": "2022-04-25T19:17:03.750168Z",
     "shell.execute_reply.started": "2022-04-25T18:20:31.862806Z"
    },
    "papermill": {
     "duration": 0.454458,
     "end_time": "2022-04-25T19:17:03.750304",
     "exception": false,
     "start_time": "2022-04-25T19:17:03.295846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# emotion='Sing Angry'\n",
    "# path = 'RAVD/Actor_01/03-02-05-01-01-01-01.wav'\n",
    "# data, sampling_rate = librosa.load(path)\n",
    "# create_waveplot(data, sampling_rate, emotion)\n",
    "# Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f55752af-56ed-489c-82ad-6bd3aa4b3c6b",
    "_uuid": "aaa11732-ab21-471e-98ea-86e993fe9aa1",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:03.925254Z",
     "iopub.status.busy": "2022-04-25T19:17:03.924685Z",
     "iopub.status.idle": "2022-04-25T19:17:04.336792Z",
     "shell.execute_reply": "2022-04-25T19:17:04.337220Z",
     "shell.execute_reply.started": "2022-04-25T18:20:32.284791Z"
    },
    "papermill": {
     "duration": 0.501377,
     "end_time": "2022-04-25T19:17:04.337359",
     "exception": false,
     "start_time": "2022-04-25T19:17:03.835982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# emotion='Sing Very Angry' \n",
    "# path = 'RAVD/Actor_01/03-02-05-02-01-01-01.wav'\n",
    "# data, sampling_rate = librosa.load(path)\n",
    "# create_waveplot(data, sampling_rate, emotion)\n",
    "# Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd1806f1-d8a1-4e41-a0e2-17a6c2ee41dc",
    "_uuid": "d5d08055-1801-45f3-9a1f-a625543bb3a8",
    "papermill": {
     "duration": 0.098118,
     "end_time": "2022-04-25T19:17:04.535673",
     "exception": false,
     "start_time": "2022-04-25T19:17:04.437555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Adding augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.098009,
     "end_time": "2022-04-25T19:17:04.731489",
     "exception": false,
     "start_time": "2022-04-25T19:17:04.633480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Definition:\n",
    "* Data augmentation is the process by which we create new synthetic training samples by adding small perturbations on our initial training set.\n",
    "* The objective is to make our model invariant to those perturbations and enhace its ability to generalize.\n",
    "* In order to this to work adding the perturbations must conserve the same label as the original training sample.\n",
    "* In images data augmention can be performed by shifting the image, zooming, rotating ...\n",
    "* In our case we will add noise, stretch and roll, pitch shift ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b249fc24-d1f1-437d-80e6-174e8453da8f",
    "_uuid": "7742f44f-b268-4b59-8185-36e7313d994a",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:04.935034Z",
     "iopub.status.busy": "2022-04-25T19:17:04.934078Z",
     "iopub.status.idle": "2022-04-25T19:17:05.090729Z",
     "shell.execute_reply": "2022-04-25T19:17:05.090197Z",
     "shell.execute_reply.started": "2022-04-25T18:20:32.787191Z"
    },
    "papermill": {
     "duration": 0.263512,
     "end_time": "2022-04-25T19:17:05.090830",
     "exception": false,
     "start_time": "2022-04-25T19:17:04.827318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data, speed_factor = 1.25):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "def lower_speed(data, speed_factor = 0.75):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "# taking any example and checking for techniques.\n",
    "path = path = 'RAVD/Actor_01/03-01-05-01-01-01-01.wav'\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "47835287-183e-4152-902e-cb6bb390b36c",
    "_uuid": "0af9e19e-92bc-4262-8ca7-20307e328acd",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:05.288223Z",
     "iopub.status.busy": "2022-04-25T19:17:05.287312Z",
     "iopub.status.idle": "2022-04-25T19:17:05.427794Z",
     "shell.execute_reply": "2022-04-25T19:17:05.428279Z",
     "shell.execute_reply.started": "2022-04-25T18:20:32.999270Z"
    },
    "papermill": {
     "duration": 0.242465,
     "end_time": "2022-04-25T19:17:05.428442",
     "exception": false,
     "start_time": "2022-04-25T19:17:05.185977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "x = noise(data)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "867418b6-84c8-4afe-9253-912cfe11b20f",
    "_uuid": "c9d85f0d-2d2c-4be2-9577-b597e20f4a20",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:05.643559Z",
     "iopub.status.busy": "2022-04-25T19:17:05.642452Z",
     "iopub.status.idle": "2022-04-25T19:17:06.341306Z",
     "shell.execute_reply": "2022-04-25T19:17:06.340801Z",
     "shell.execute_reply.started": "2022-04-25T18:20:33.183986Z"
    },
    "papermill": {
     "duration": 0.808939,
     "end_time": "2022-04-25T19:17:06.341428",
     "exception": false,
     "start_time": "2022-04-25T19:17:05.532489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "x = stretch(data)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ecf5b48f-15a6-451a-b2b9-bacba7173fd8",
    "_uuid": "8bb38c4d-24bd-443f-8c96-6fcccfb8f781",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:06.560971Z",
     "iopub.status.busy": "2022-04-25T19:17:06.560308Z",
     "iopub.status.idle": "2022-04-25T19:17:06.692541Z",
     "shell.execute_reply": "2022-04-25T19:17:06.692986Z",
     "shell.execute_reply.started": "2022-04-25T18:20:33.981587Z"
    },
    "papermill": {
     "duration": 0.243644,
     "end_time": "2022-04-25T19:17:06.693139",
     "exception": false,
     "start_time": "2022-04-25T19:17:06.449495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "x = shift(data)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "69c72492-3a27-49ce-b0e9-59a760c079a9",
    "_uuid": "d69f44d9-2f5e-41ea-a924-f56164eb7ab0",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:06.925120Z",
     "iopub.status.busy": "2022-04-25T19:17:06.924074Z",
     "iopub.status.idle": "2022-04-25T19:17:07.168774Z",
     "shell.execute_reply": "2022-04-25T19:17:07.169265Z",
     "shell.execute_reply.started": "2022-04-25T18:20:34.147428Z"
    },
    "papermill": {
     "duration": 0.362171,
     "end_time": "2022-04-25T19:17:07.169412",
     "exception": false,
     "start_time": "2022-04-25T19:17:06.807241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "x = pitch(data, sample_rate)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:07.408430Z",
     "iopub.status.busy": "2022-04-25T19:17:07.407186Z",
     "iopub.status.idle": "2022-04-25T19:17:07.554610Z",
     "shell.execute_reply": "2022-04-25T19:17:07.554078Z",
     "shell.execute_reply.started": "2022-04-25T18:20:34.451009Z"
    },
    "papermill": {
     "duration": 0.26862,
     "end_time": "2022-04-25T19:17:07.554720",
     "exception": false,
     "start_time": "2022-04-25T19:17:07.286100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "x = higher_speed(data)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:07.801206Z",
     "iopub.status.busy": "2022-04-25T19:17:07.800191Z",
     "iopub.status.idle": "2022-04-25T19:17:07.978823Z",
     "shell.execute_reply": "2022-04-25T19:17:07.979356Z",
     "shell.execute_reply.started": "2022-04-25T18:20:34.641098Z"
    },
    "papermill": {
     "duration": 0.303559,
     "end_time": "2022-04-25T19:17:07.979485",
     "exception": false,
     "start_time": "2022-04-25T19:17:07.675926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "x = lower_speed(data)\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b0f0f1bc-26cb-4e46-afe4-6a87f340d216",
    "_uuid": "2f180b40-2a67-4f2e-bad4-70489a4e7270",
    "papermill": {
     "duration": 0.122559,
     "end_time": "2022-04-25T19:17:08.231073",
     "exception": false,
     "start_time": "2022-04-25T19:17:08.108514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center> Feature Extraction</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34f5928d-28ba-44eb-a208-747dff0496fa",
    "_uuid": "933364f6-33c2-4836-b004-5d8e273aa95c",
    "papermill": {
     "duration": 0.123425,
     "end_time": "2022-04-25T19:17:08.477355",
     "exception": false,
     "start_time": "2022-04-25T19:17:08.353930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we understand, the data provided from audio cannot be understood by the models directly, so we need to convert them into an understandable format for which feature extraction is used.\n",
    "The audio signal is a three-dimensional signal in which three axes represent time, amplitude and frequency.\n",
    "\n",
    "\n",
    "Looking at the waveplots above seems clear (from an eye test) that the waveform itself may not necessarily yield clear class identifying information. Infact they look quite similar.<br/>  \n",
    "It turns out one of the best tool to feature extract from audio waveforms ( and digital signal in general) is   **Mel Frequency Cepstral Coefficents (MFCCs)**.  Below we will go through a brief technical discussion, just to see how MFCCs works\n",
    "\n",
    "## add to references \n",
    "* All the infos about feature extraction and audio processing were taken from https://medium.com/comet-ml/applyingmachinelearningtoaudioanalysis-utm-source-kdnuggets11-19-e160b069e88\n",
    "* Mel Frequency Cepstral Coefficients (MFCCs), introduced by Davis and Mermelstein in 1980."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c409646e-553a-432b-b79f-2d4339243c62",
    "_uuid": "2bba8bf9-d3d6-49c7-b3c6-8ca6fd55426a",
    "papermill": {
     "duration": 0.127241,
     "end_time": "2022-04-25T19:17:08.729937",
     "exception": false,
     "start_time": "2022-04-25T19:17:08.602696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "This feature is one of the most important method to extract a feature of an audio signal and is used majorly whenever working on audio signals. The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.04*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.70):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.8):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def higher_speed(data, speed_factor = 1.25):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n",
    "\n",
    "def lower_speed(data, speed_factor = 0.75):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "495d6361-676f-4ef5-9b74-2f16e7157e61",
    "_uuid": "588ccbb7-3456-49da-9c75-5fcf5f21cb0e",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:08.993247Z",
     "iopub.status.busy": "2022-04-25T19:17:08.992107Z",
     "iopub.status.idle": "2022-04-25T19:17:08.995131Z",
     "shell.execute_reply": "2022-04-25T19:17:08.994577Z",
     "shell.execute_reply.started": "2022-04-25T18:20:34.910498Z"
    },
    "papermill": {
     "duration": 0.140976,
     "end_time": "2022-04-25T19:17:08.995231",
     "exception": false,
     "start_time": "2022-04-25T19:17:08.854255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sample_rate = 22050\n",
    "\n",
    "def extract_features(data):\n",
    "    \n",
    "    result = np.array([])\n",
    "    \n",
    "    #mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=42) #42 mfcc so we get frames of ~60 ms\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=58)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    result = np.array(mfccs_processed)\n",
    "     \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=3, offset=0.5, res_type='kaiser_fast') \n",
    "    \n",
    "    #without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    #noised\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    #stretched\n",
    "    stretch_data = stretch(data)\n",
    "    res3 = extract_features(stretch_data)\n",
    "    result = np.vstack((result, res3))\n",
    "    \n",
    "    #shifted\n",
    "    shift_data = shift(data)\n",
    "    res4 = extract_features(shift_data)\n",
    "    result = np.vstack((result, res4))\n",
    "    \n",
    "    #pitched\n",
    "    pitch_data = pitch(data, sample_rate)\n",
    "    res5 = extract_features(pitch_data)\n",
    "    result = np.vstack((result, res5)) \n",
    "    \n",
    "    #speed up\n",
    "    higher_speed_data = higher_speed(data)\n",
    "    res6 = extract_features(higher_speed_data)\n",
    "    result = np.vstack((result, res6))\n",
    "    \n",
    "    #speed down\n",
    "    lower_speed_data = higher_speed(data)\n",
    "    res7 = extract_features(lower_speed_data)\n",
    "    result = np.vstack((result, res7))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:7: FutureWarning: Pass rate=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:14: FutureWarning: Pass sr=22050, n_steps=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:17: FutureWarning: Pass rate=1.25 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, speed_factor)\n",
      "480it [01:40,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check shapes:\n",
      "features: 3360, labels: 3360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not DATA_FRAMES:\n",
    " \n",
    "    load_df = SAVEE_df\n",
    "    df_X, df_Y = [], []\n",
    "    for path, emotion in tqdm(zip(load_df.path, load_df.labels)):\n",
    "        path = path.replace(\"//\",\"/\")\n",
    "        try:\n",
    "            features = get_features(path)\n",
    "            #adding augmentation, get_features return a multi dimensional array (for each augmentation), so we have to use a loop to fill the df\n",
    "            for elem in features: \n",
    "                df_X.append(elem)        \n",
    "                df_Y.append(emotion)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f'Check shapes:\\nfeatures: {len(df_X)}, labels: {len(df_Y)}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sad', 'surprise', 'fear', 'angry', 'disgust', 'happy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:7: FutureWarning: Pass rate=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:14: FutureWarning: Pass sr=22050, n_steps=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:17: FutureWarning: Pass rate=1.25 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, speed_factor)\n",
      "360it [01:19,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check shapes:\n",
      "features: 2520, labels: 2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not DATA_FRAMES:\n",
    "#     path = 'final_df.csv'\n",
    "#     load_df = pd.read_csv(path)\n",
    "    load_df = SAVEE_df\n",
    "    load_df = load_df[load_df.labels != 'neutral']\n",
    "    print(set(load_df.labels))\n",
    "    df_X, df_Y = [], []\n",
    "    for path, emotion in tqdm(zip(load_df.path, load_df.labels)):\n",
    "        path = path.replace(\"//\",\"/\")\n",
    "#         print(path)\n",
    "        try:\n",
    "            features = get_features(path)\n",
    "            #adding augmentation, get_features return a multi dimensional array (for each augmentation), so we have to use a loop to fill the df\n",
    "            for elem in features: \n",
    "                df_X.append(elem)        \n",
    "                df_Y.append(emotion)\n",
    "        except:\n",
    "            pass\n",
    "    print(f'Check shapes:\\nfeatures: {len(df_X)}, labels: {len(df_Y)}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "078e399f-f2c0-4d25-b650-11d7d127bcad",
    "_uuid": "5c82f628-b3c0-4638-ae9a-a0a5fccb7639",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:09.254305Z",
     "iopub.status.busy": "2022-04-25T19:17:09.253468Z",
     "iopub.status.idle": "2022-04-25T19:17:09.256420Z",
     "shell.execute_reply": "2022-04-25T19:17:09.255962Z",
     "shell.execute_reply.started": "2022-04-25T18:20:34.930316Z"
    },
    "papermill": {
     "duration": 0.135563,
     "end_time": "2022-04-25T19:17:09.256536",
     "exception": false,
     "start_time": "2022-04-25T19:17:09.120973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not DATA_FRAMES:\n",
    "    \n",
    "#     female_X, female_Y = [], []\n",
    "#     for path, emotion in zip(Females.path, Females.labels):\n",
    "#         path = path.replace(\"//\",\"/\")\n",
    "#         features = get_features(path)\n",
    "#         #adding augmentation, get_features return a multi dimensional array (for each augmentation), so we have to use a loop to fill the df\n",
    "#         for elem in features: \n",
    "#             female_X.append(elem)        \n",
    "#             female_Y.append(emotion)\n",
    "    \n",
    "\n",
    "#     male_X, male_Y = [], []\n",
    "#     for path, emotion in zip(Males.path, Males.labels):\n",
    "#         path = path.replace(\"//\",\"/\")\n",
    "#         features = get_features(path)\n",
    "#         for elem in features:\n",
    "#             male_X.append(elem)\n",
    "#             male_Y.append(emotion)\n",
    "            \n",
    "#     print(f'Check shapes:\\nFemale features: {len(female_X)}, labels: {len(female_Y)}\\nMale features:   {len(male_X)}, labels: {len(male_Y)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a7defac7-9b53-44e4-9dcb-62efc952a60f",
    "_uuid": "eeedb444-b208-4303-a886-6f4ac9bcd4b9",
    "papermill": {
     "duration": 0.333667,
     "end_time": "2022-04-25T19:17:12.454809",
     "exception": false,
     "start_time": "2022-04-25T19:17:12.121142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>Data Preparation\n",
    "As of now we have extracted the data, now we need to normalize and split our data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "8b957998-6082-49eb-817a-a515aede8ca0",
    "_uuid": "ac744cf0-b81c-4d73-b7d4-f46aad3d8dc4",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:12.896043Z",
     "iopub.status.busy": "2022-04-25T19:17:12.895118Z",
     "iopub.status.idle": "2022-04-25T19:17:12.897765Z",
     "shell.execute_reply": "2022-04-25T19:17:12.896993Z",
     "shell.execute_reply.started": "2022-04-25T18:20:36.908572Z"
    },
    "papermill": {
     "duration": 0.225635,
     "end_time": "2022-04-25T19:17:12.897904",
     "exception": false,
     "start_time": "2022-04-25T19:17:12.672269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "74df1a59-4147-48e3-a126-9864ea08ce89",
    "_uuid": "58bb4e1a-0eeb-40b8-ae0c-f17fdfd2387e",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:13.188180Z",
     "iopub.status.busy": "2022-04-25T19:17:13.187298Z",
     "iopub.status.idle": "2022-04-25T19:17:13.190493Z",
     "shell.execute_reply": "2022-04-25T19:17:13.189927Z",
     "shell.execute_reply.started": "2022-04-25T18:20:36.917533Z"
    },
    "papermill": {
     "duration": 0.148687,
     "end_time": "2022-04-25T19:17:13.190593",
     "exception": false,
     "start_time": "2022-04-25T19:17:13.041906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# female_X = Females_Features.iloc[: ,:-1].values\n",
    "# female_Y = Females_Features['labels'].values\n",
    "\n",
    "# male_X = Males_Features.iloc[: ,:-1].values\n",
    "# male_Y = Males_Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "c81ac313-e56c-4c47-8de9-47c9ce51c9ba",
    "_uuid": "b99d9b98-3984-43b1-ad27-3058d6f4b5db",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:13.465784Z",
     "iopub.status.busy": "2022-04-25T19:17:13.444057Z",
     "iopub.status.idle": "2022-04-25T19:17:13.485695Z",
     "shell.execute_reply": "2022-04-25T19:17:13.486148Z",
     "shell.execute_reply.started": "2022-04-25T18:20:36.946334Z"
    },
    "papermill": {
     "duration": 0.17347,
     "end_time": "2022-04-25T19:17:13.486335",
     "exception": false,
     "start_time": "2022-04-25T19:17:13.312865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # As this is a multiclass classification problem onehotencoding our Y.\n",
    "# encoder = OneHotEncoder()\n",
    "\n",
    "# female_Y = encoder.fit_transform(np.array(female_Y).reshape(-1,1)).toarray()\n",
    "# male_Y = encoder.fit_transform(np.array(male_Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry', 'disgust', 'fear', 'happy', 'sad', 'surprise'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y.\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "df_Y = encoder.fit_transform(np.array(df_Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = np.array(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform([['sad']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a7492ee6-3b5b-4a4d-ac73-facf7e5d3d35",
    "_uuid": "267c61f3-0658-46e9-bcde-889a8dff29e1",
    "papermill": {
     "duration": 0.126487,
     "end_time": "2022-04-25T19:17:13.738399",
     "exception": false,
     "start_time": "2022-04-25T19:17:13.611912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.123723,
     "end_time": "2022-04-25T19:17:13.985006",
     "exception": false,
     "start_time": "2022-04-25T19:17:13.861283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just for adding more proves that gender separation have sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:14.240657Z",
     "iopub.status.busy": "2022-04-25T19:17:14.239308Z",
     "iopub.status.idle": "2022-04-25T19:17:14.308047Z",
     "shell.execute_reply": "2022-04-25T19:17:14.307478Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.002019Z"
    },
    "papermill": {
     "duration": 0.197892,
     "end_time": "2022-04-25T19:17:14.308154",
     "exception": false,
     "start_time": "2022-04-25T19:17:14.110262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nogender_X = np.concatenate((female_X, male_X))\n",
    "# nogender_Y = np.concatenate((female_Y, male_Y))\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(nogender_X, nogender_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "# x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2016, 58), (2016, 6), (504, 58), (504, 6))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_X, df_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "7faf1771-a5e8-4e39-aff7-9177bfdb7eab",
    "_uuid": "ca782f6d-060b-42b4-ab37-0ace11841509",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:14.564214Z",
     "iopub.status.busy": "2022-04-25T19:17:14.563638Z",
     "iopub.status.idle": "2022-04-25T19:17:14.594952Z",
     "shell.execute_reply": "2022-04-25T19:17:14.595470Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.084292Z"
    },
    "papermill": {
     "duration": 0.163592,
     "end_time": "2022-04-25T19:17:14.595611",
     "exception": false,
     "start_time": "2022-04-25T19:17:14.432019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_trainF, x_testF, y_trainF, y_testF = train_test_split(female_X, female_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "# x_trainF.shape, y_trainF.shape, x_testF.shape, y_testF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "989d4298-07cf-4875-81c8-f64950eb598a",
    "_uuid": "094de711-d89e-49ab-8afa-57bb9a2856ab",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:14.856697Z",
     "iopub.status.busy": "2022-04-25T19:17:14.855595Z",
     "iopub.status.idle": "2022-04-25T19:17:14.876025Z",
     "shell.execute_reply": "2022-04-25T19:17:14.876482Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.127021Z"
    },
    "papermill": {
     "duration": 0.156256,
     "end_time": "2022-04-25T19:17:14.876612",
     "exception": false,
     "start_time": "2022-04-25T19:17:14.720356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_trainM, x_testM, y_trainM, y_testM = train_test_split(male_X, male_Y, random_state=0, test_size=0.20, shuffle=True)\n",
    "# x_trainM.shape, y_trainM.shape, x_testM.shape, y_testM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd518403-6a48-4430-b95c-7597b8708d8e",
    "_uuid": "87cbc221-1eed-48b5-8113-e6764762485e",
    "papermill": {
     "duration": 0.126029,
     "end_time": "2022-04-25T19:17:15.127908",
     "exception": false,
     "start_time": "2022-04-25T19:17:15.001879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  \n",
    "We are going to scale our features throught the StandarScaler module, it standardize the features in a **Normal curve**, i.e.:<br><br>\n",
    "  <center> $Z = (X -{\\mu})/{\\sigma}$. </center><br>\n",
    "*Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "f4640e2b-eaed-41d7-81b4-ba65bb8e0486",
    "_uuid": "0ee2bea2-7ee3-43ce-ae2a-cd4a28f1c41f",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:15.383326Z",
     "iopub.status.busy": "2022-04-25T19:17:15.382237Z",
     "iopub.status.idle": "2022-04-25T19:17:15.541976Z",
     "shell.execute_reply": "2022-04-25T19:17:15.541488Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.162059Z"
    },
    "papermill": {
     "duration": 0.291115,
     "end_time": "2022-04-25T19:17:15.542087",
     "exception": false,
     "start_time": "2022-04-25T19:17:15.250972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# x_trainF = scaler.fit_transform(x_trainF)\n",
    "# x_testF = scaler.transform(x_testF)\n",
    "\n",
    "# x_trainM = scaler.fit_transform(x_trainM)\n",
    "# x_testM = scaler.transform(x_testM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "365d8795-2307-48cf-b01c-a4028253126b",
    "_uuid": "254dc31b-fb2b-4af2-b9e7-e3c0e9c0153e",
    "papermill": {
     "duration": 0.124441,
     "end_time": "2022-04-25T19:17:15.792160",
     "exception": false,
     "start_time": "2022-04-25T19:17:15.667719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making our data compatible to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:16.049567Z",
     "iopub.status.busy": "2022-04-25T19:17:16.048803Z",
     "iopub.status.idle": "2022-04-25T19:17:16.052589Z",
     "shell.execute_reply": "2022-04-25T19:17:16.052066Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.336452Z"
    },
    "papermill": {
     "duration": 0.137231,
     "end_time": "2022-04-25T19:17:16.052697",
     "exception": false,
     "start_time": "2022-04-25T19:17:15.915466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2016, 58, 1), (2016, 6), (504, 58, 1), (504, 6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape , x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "c22879c0-9f9f-4895-8ec2-2b5a5041842a",
    "_uuid": "7b6187b7-751b-4f3f-91ed-c114778cfc44",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:16.310534Z",
     "iopub.status.busy": "2022-04-25T19:17:16.309740Z",
     "iopub.status.idle": "2022-04-25T19:17:16.313377Z",
     "shell.execute_reply": "2022-04-25T19:17:16.312954Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.350123Z"
    },
    "papermill": {
     "duration": 0.135646,
     "end_time": "2022-04-25T19:17:16.313480",
     "exception": false,
     "start_time": "2022-04-25T19:17:16.177834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_trainF = np.expand_dims(x_trainF, axis=2)\n",
    "# x_testF = np.expand_dims(x_testF, axis=2)\n",
    "# x_trainF.shape, y_trainF.shape, x_testF.shape, y_testF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "786a150e-181d-45d3-972d-1c688adcdb6d",
    "_uuid": "5fc3272f-e82f-4645-83bd-917876decca5",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:16.572826Z",
     "iopub.status.busy": "2022-04-25T19:17:16.571933Z",
     "iopub.status.idle": "2022-04-25T19:17:16.575995Z",
     "shell.execute_reply": "2022-04-25T19:17:16.575470Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.364716Z"
    },
    "papermill": {
     "duration": 0.13778,
     "end_time": "2022-04-25T19:17:16.576109",
     "exception": false,
     "start_time": "2022-04-25T19:17:16.438329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_trainM = np.expand_dims(x_trainM, axis=2)\n",
    "# x_testM = np.expand_dims(x_testM, axis=2)\n",
    "# x_trainM.shape, y_trainM.shape, x_testM.shape, y_testM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9d8ce9e-3075-4a91-9fa2-bb6f468b3ab9",
    "_uuid": "3a24a0e5-62b8-47a8-8623-fdb122fbb967",
    "papermill": {
     "duration": 0.127454,
     "end_time": "2022-04-25T19:17:16.830224",
     "exception": false,
     "start_time": "2022-04-25T19:17:16.702770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>Modeling<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "3784657e-a214-4643-9b37-c1cdc0d779b5",
    "_uuid": "276d227e-ccc8-47a8-b7f0-e1f9af5b01f8",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:17.101105Z",
     "iopub.status.busy": "2022-04-25T19:17:17.100403Z",
     "iopub.status.idle": "2022-04-25T19:17:21.235847Z",
     "shell.execute_reply": "2022-04-25T19:17:21.235210Z",
     "shell.execute_reply.started": "2022-04-25T18:20:37.379005Z"
    },
    "papermill": {
     "duration": 4.279182,
     "end_time": "2022-04-25T19:17:21.235962",
     "exception": false,
     "start_time": "2022-04-25T19:17:16.956780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, AveragePooling1D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "617f366b-db5a-4a5f-b2ec-c989d92220c7",
    "_uuid": "02667e51-976b-45be-9424-c6031256dc5b",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:21.933978Z",
     "iopub.status.busy": "2022-04-25T19:17:21.933334Z",
     "iopub.status.idle": "2022-04-25T19:17:21.940100Z",
     "shell.execute_reply": "2022-04-25T19:17:21.939439Z",
     "shell.execute_reply.started": "2022-04-25T18:20:42.621273Z"
    },
    "papermill": {
     "duration": 0.579049,
     "end_time": "2022-04-25T19:17:21.940241",
     "exception": false,
     "start_time": "2022-04-25T19:17:21.361192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "03735553-216e-4a5d-932d-a7084ec7c3d3",
    "_uuid": "0f302020-e0cc-4583-8396-b65e53f9bdbc",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:23.665494Z",
     "iopub.status.busy": "2022-04-25T19:17:23.664527Z",
     "iopub.status.idle": "2022-04-25T19:17:23.671860Z",
     "shell.execute_reply": "2022-04-25T19:17:23.671185Z",
     "shell.execute_reply.started": "2022-04-25T18:20:43.186158Z"
    },
    "papermill": {
     "duration": 1.606706,
     "end_time": "2022-04-25T19:17:23.671972",
     "exception": false,
     "start_time": "2022-04-25T19:17:22.065266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 08:13:32.260060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "025457f6-da9c-49c5-820c-0258547185cb",
    "_uuid": "3ed66eef-3c8d-40f6-bf6c-2dae3f074d7e",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:24.036951Z",
     "iopub.status.busy": "2022-04-25T19:17:24.036245Z",
     "iopub.status.idle": "2022-04-25T19:17:24.040921Z",
     "shell.execute_reply": "2022-04-25T19:17:24.041349Z",
     "shell.execute_reply.started": "2022-04-25T18:20:44.896134Z"
    },
    "papermill": {
     "duration": 0.156222,
     "end_time": "2022-04-25T19:17:24.041484",
     "exception": false,
     "start_time": "2022-04-25T19:17:23.885262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    def build_model(in_shape):\n",
    "        \n",
    "        model=Sequential()\n",
    "        model.add(Conv1D(256, kernel_size=6, strides=1, padding='same', activation='relu', input_shape=(in_shape, 1)))\n",
    "        model.add(AveragePooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "\n",
    "        model.add(Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu'))\n",
    "        model.add(AveragePooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "\n",
    "        model.add(Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu'))\n",
    "        model.add(AveragePooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv1D(64, kernel_size=6, strides=1, padding='same', activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=4, strides = 2, padding = 'same'))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=32, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Dense(units=6, activation='softmax'))\n",
    "        model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "          \n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "0669ff45-5978-45bb-aa26-2e8f419f98e7",
    "_uuid": "ca817c54-848e-4bc3-8182-48f792a3a616",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:24.300202Z",
     "iopub.status.busy": "2022-04-25T19:17:24.299357Z",
     "iopub.status.idle": "2022-04-25T19:17:24.302252Z",
     "shell.execute_reply": "2022-04-25T19:17:24.301805Z",
     "shell.execute_reply.started": "2022-04-25T18:20:44.917966Z"
    },
    "papermill": {
     "duration": 0.135428,
     "end_time": "2022-04-25T19:17:24.302362",
     "exception": false,
     "start_time": "2022-04-25T19:17:24.166934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_build_summary(mod_dim, tr_features, val_features, val_labels):\n",
    "    model = build_model(mod_dim)\n",
    "    model.summary()\n",
    "    \n",
    "    score = model.evaluate(val_features, val_labels, verbose = 1)\n",
    "    accuracy = 100*score[1]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8df4fe0c-88ee-4170-9835-188a15b06574",
    "_uuid": "e4fcfecf-a921-45ee-a37a-ac8674d790e4",
    "papermill": {
     "duration": 0.128382,
     "end_time": "2022-04-25T19:17:24.557411",
     "exception": false,
     "start_time": "2022-04-25T19:17:24.429029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*ReduceLROnPlateau* reduce learning rate when a metric has stopped improving.<br>\n",
    "\n",
    "Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "6f0e6211-dcfe-4ebc-abe8-57ad3d31c0fb",
    "_uuid": "6f9617eb-6955-4264-86ff-16de5fa2b4ff",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:24.818463Z",
     "iopub.status.busy": "2022-04-25T19:17:24.817496Z",
     "iopub.status.idle": "2022-04-25T19:17:24.820382Z",
     "shell.execute_reply": "2022-04-25T19:17:24.819857Z",
     "shell.execute_reply.started": "2022-04-25T18:20:44.929946Z"
    },
    "papermill": {
     "duration": 0.137743,
     "end_time": "2022-04-25T19:17:24.820488",
     "exception": false,
     "start_time": "2022-04-25T19:17:24.682745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=4, min_lr=0.000001)\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "b9dbc777-4949-4982-8534-48dc46cc6dcd",
    "_uuid": "657294c0-b559-421f-9f50-3ea13b1ed691",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:25.185617Z",
     "iopub.status.busy": "2022-04-25T19:17:25.184676Z",
     "iopub.status.idle": "2022-04-25T19:17:25.199009Z",
     "shell.execute_reply": "2022-04-25T19:17:25.198387Z",
     "shell.execute_reply.started": "2022-04-25T18:20:44.941371Z"
    },
    "papermill": {
     "duration": 0.250104,
     "end_time": "2022-04-25T19:17:25.199149",
     "exception": false,
     "start_time": "2022-04-25T19:17:24.949045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_graphs(history):\n",
    "    epochs = [i for i in range(n_epochs)]\n",
    "    fig , ax = plt.subplots(1,2)\n",
    "    train_acc = history.history['accuracy']\n",
    "    train_loss = history.history['loss']\n",
    "    test_acc = history.history['val_accuracy']\n",
    "    test_loss = history.history['val_loss']\n",
    "\n",
    "    fig.set_size_inches(30,12)\n",
    "    ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "    ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "    ax[0].set_title('Training & Testing Loss')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "    ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "    ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "    ax[1].set_title('Training & Testing Accuracy')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d0162cd2-734a-45cf-bd6f-1d33037feb36",
    "_uuid": "b8db12a0-b5f5-4831-ae7c-ce3b80b64f30",
    "papermill": {
     "duration": 0.217496,
     "end_time": "2022-04-25T19:17:25.627537",
     "exception": false,
     "start_time": "2022-04-25T19:17:25.410041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Summary and Pre-training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:26.102229Z",
     "iopub.status.busy": "2022-04-25T19:17:26.101416Z",
     "iopub.status.idle": "2022-04-25T19:17:30.647004Z",
     "shell.execute_reply": "2022-04-25T19:17:30.645623Z",
     "shell.execute_reply.started": "2022-04-25T18:20:44.960627Z"
    },
    "papermill": {
     "duration": 4.788263,
     "end_time": "2022-04-25T19:17:30.647112",
     "exception": false,
     "start_time": "2022-04-25T19:17:25.858849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 58, 256)           1792      \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 29, 256)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 29, 128)           196736    \n",
      "                                                                 \n",
      " average_pooling1d_1 (Averag  (None, 15, 128)          0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 15, 128)           98432     \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (None, 8, 128)           0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 128)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 8, 64)             49216     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 354,598\n",
      "Trainable params: 354,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7936 - accuracy: 0.1468\n"
     ]
    }
   ],
   "source": [
    "total_model = model_build_summary(x_train.shape[1], x_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "853d7c4b-3942-4e2e-92c8-6f1416d07bfd",
    "_uuid": "fbc003e4-b7f4-4fd6-9540-67adf0a11d6a",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:30.922439Z",
     "iopub.status.busy": "2022-04-25T19:17:30.921576Z",
     "iopub.status.idle": "2022-04-25T19:17:32.070636Z",
     "shell.execute_reply": "2022-04-25T19:17:32.071240Z",
     "shell.execute_reply.started": "2022-04-25T18:20:50.907005Z"
    },
    "papermill": {
     "duration": 1.291361,
     "end_time": "2022-04-25T19:17:32.071421",
     "exception": false,
     "start_time": "2022-04-25T19:17:30.780060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# female_model = model_build_summary(x_trainF.shape[1], x_trainF, x_testF, y_testF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "dc2e6c56-87b3-4830-aa1d-2bb0ff9b4e9d",
    "_uuid": "f4236892-65fe-43c6-a430-66fd9ce42fd3",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:32.354710Z",
     "iopub.status.busy": "2022-04-25T19:17:32.353709Z",
     "iopub.status.idle": "2022-04-25T19:17:33.278363Z",
     "shell.execute_reply": "2022-04-25T19:17:33.277496Z",
     "shell.execute_reply.started": "2022-04-25T18:20:52.324643Z"
    },
    "papermill": {
     "duration": 1.070913,
     "end_time": "2022-04-25T19:17:33.278471",
     "exception": false,
     "start_time": "2022-04-25T19:17:32.207558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# male_model = model_build_summary(x_trainM.shape[1], x_trainM, x_testM, y_testM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2b79fb2-daf8-4a17-a012-a37263f9a8d0",
    "_uuid": "f1d4a537-a729-47ea-b935-4fe454580ecf",
    "papermill": {
     "duration": 0.141101,
     "end_time": "2022-04-25T19:17:33.561684",
     "exception": false,
     "start_time": "2022-04-25T19:17:33.420583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:17:33.850230Z",
     "iopub.status.busy": "2022-04-25T19:17:33.849039Z",
     "iopub.status.idle": "2022-04-25T19:29:15.199561Z",
     "shell.execute_reply": "2022-04-25T19:29:15.198652Z",
     "shell.execute_reply.started": "2022-04-25T18:20:53.748478Z"
    },
    "papermill": {
     "duration": 701.497871,
     "end_time": "2022-04-25T19:29:15.199675",
     "exception": false,
     "start_time": "2022-04-25T19:17:33.701804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5979 - accuracy: 0.3125 - val_loss: 1.4276 - val_accuracy: 0.4107 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.3609 - accuracy: 0.4464 - val_loss: 1.2951 - val_accuracy: 0.4623 - lr: 0.0010\n",
      "Epoch 3/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.3007 - accuracy: 0.4583 - val_loss: 1.1313 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 4/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.1788 - accuracy: 0.5089 - val_loss: 1.0518 - val_accuracy: 0.5933 - lr: 0.0010\n",
      "Epoch 5/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.1357 - accuracy: 0.5337 - val_loss: 1.0180 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 6/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0885 - accuracy: 0.5506 - val_loss: 1.0066 - val_accuracy: 0.5794 - lr: 0.0010\n",
      "Epoch 7/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0306 - accuracy: 0.5813 - val_loss: 0.9132 - val_accuracy: 0.6131 - lr: 0.0010\n",
      "Epoch 8/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.9824 - accuracy: 0.6012 - val_loss: 0.8910 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 9/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.9519 - accuracy: 0.6111 - val_loss: 0.8316 - val_accuracy: 0.6587 - lr: 0.0010\n",
      "Epoch 10/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.8764 - accuracy: 0.6498 - val_loss: 0.9255 - val_accuracy: 0.6151 - lr: 0.0010\n",
      "Epoch 11/75\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.8660 - accuracy: 0.6443 - val_loss: 0.7422 - val_accuracy: 0.7063 - lr: 0.0010\n",
      "Epoch 12/75\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.8100 - accuracy: 0.6701 - val_loss: 0.7878 - val_accuracy: 0.6746 - lr: 0.0010\n",
      "Epoch 13/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.7823 - accuracy: 0.6801 - val_loss: 0.6764 - val_accuracy: 0.7222 - lr: 0.0010\n",
      "Epoch 14/75\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.7027 - accuracy: 0.7252 - val_loss: 0.5749 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Epoch 15/75\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.6461 - accuracy: 0.7411 - val_loss: 0.5823 - val_accuracy: 0.7817 - lr: 0.0010\n",
      "Epoch 16/75\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.5974 - accuracy: 0.7560 - val_loss: 0.5327 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Epoch 17/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.6018 - accuracy: 0.7629 - val_loss: 0.5077 - val_accuracy: 0.8234 - lr: 0.0010\n",
      "Epoch 18/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.5206 - accuracy: 0.7971 - val_loss: 0.4927 - val_accuracy: 0.8016 - lr: 0.0010\n",
      "Epoch 19/75\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.5077 - accuracy: 0.8056 - val_loss: 0.4164 - val_accuracy: 0.8373 - lr: 0.0010\n",
      "Epoch 20/75\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.4624 - accuracy: 0.8279 - val_loss: 0.3919 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 21/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.4267 - accuracy: 0.8378 - val_loss: 0.3336 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 22/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.4062 - accuracy: 0.8467 - val_loss: 0.3629 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 23/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.4039 - accuracy: 0.8388 - val_loss: 0.3831 - val_accuracy: 0.8532 - lr: 0.0010\n",
      "Epoch 24/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.3477 - accuracy: 0.8636 - val_loss: 0.3873 - val_accuracy: 0.8492 - lr: 0.0010\n",
      "Epoch 25/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.3527 - accuracy: 0.8611 - val_loss: 0.2838 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 26/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.2899 - accuracy: 0.8934 - val_loss: 0.2802 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 27/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.2781 - accuracy: 0.8953 - val_loss: 0.2968 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 28/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.2705 - accuracy: 0.9008 - val_loss: 0.2206 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 29/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.2513 - accuracy: 0.9067 - val_loss: 0.2372 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 30/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.2264 - accuracy: 0.9137 - val_loss: 0.2412 - val_accuracy: 0.9147 - lr: 0.0010\n",
      "Epoch 31/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1956 - accuracy: 0.9281 - val_loss: 0.2620 - val_accuracy: 0.9087 - lr: 0.0010\n",
      "Epoch 32/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.2175 - accuracy: 0.9241 - val_loss: 0.2157 - val_accuracy: 0.9306 - lr: 0.0010\n",
      "Epoch 33/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1839 - accuracy: 0.9350 - val_loss: 0.2240 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 34/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1834 - accuracy: 0.9320 - val_loss: 0.2317 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "Epoch 35/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1606 - accuracy: 0.9390 - val_loss: 0.2082 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 36/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.2289 - accuracy: 0.9177 - val_loss: 0.2297 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 37/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1453 - accuracy: 0.9489 - val_loss: 0.2019 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 38/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.2033 - accuracy: 0.9281 - val_loss: 0.2227 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "Epoch 39/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1551 - accuracy: 0.9479 - val_loss: 0.2046 - val_accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 40/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1498 - accuracy: 0.9514 - val_loss: 0.1735 - val_accuracy: 0.9504 - lr: 0.0010\n",
      "Epoch 41/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1322 - accuracy: 0.9583 - val_loss: 0.1760 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 42/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1174 - accuracy: 0.9524 - val_loss: 0.1755 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 43/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1539 - accuracy: 0.9454 - val_loss: 0.2051 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 44/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1240 - accuracy: 0.9578 - val_loss: 0.2235 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 45/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1023 - accuracy: 0.9658 - val_loss: 0.1698 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 46/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1056 - accuracy: 0.9633 - val_loss: 0.2584 - val_accuracy: 0.9306 - lr: 0.0010\n",
      "Epoch 47/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1162 - accuracy: 0.9593 - val_loss: 0.1697 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 48/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1121 - accuracy: 0.9603 - val_loss: 0.2069 - val_accuracy: 0.9385 - lr: 0.0010\n",
      "Epoch 49/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.1211 - accuracy: 0.9598 - val_loss: 0.1747 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 50/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0649 - accuracy: 0.9797 - val_loss: 0.1912 - val_accuracy: 0.9504 - lr: 4.0000e-04\n",
      "Epoch 51/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0570 - accuracy: 0.9831 - val_loss: 0.1652 - val_accuracy: 0.9603 - lr: 4.0000e-04\n",
      "Epoch 52/75\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.0522 - accuracy: 0.9841 - val_loss: 0.1750 - val_accuracy: 0.9544 - lr: 4.0000e-04\n",
      "Epoch 53/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0657 - accuracy: 0.9747 - val_loss: 0.1829 - val_accuracy: 0.9484 - lr: 4.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0428 - accuracy: 0.9886 - val_loss: 0.1840 - val_accuracy: 0.9464 - lr: 4.0000e-04\n",
      "Epoch 55/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 0.1737 - val_accuracy: 0.9504 - lr: 4.0000e-04\n",
      "Epoch 56/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.1765 - val_accuracy: 0.9444 - lr: 4.0000e-04\n",
      "Epoch 57/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0468 - accuracy: 0.9856 - val_loss: 0.1891 - val_accuracy: 0.9504 - lr: 4.0000e-04\n",
      "Epoch 58/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0416 - accuracy: 0.9896 - val_loss: 0.1842 - val_accuracy: 0.9464 - lr: 4.0000e-04\n",
      "Epoch 59/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.2007 - val_accuracy: 0.9444 - lr: 4.0000e-04\n",
      "Epoch 60/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0508 - accuracy: 0.9802 - val_loss: 0.2143 - val_accuracy: 0.9464 - lr: 4.0000e-04\n",
      "Epoch 61/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0355 - accuracy: 0.9866 - val_loss: 0.1981 - val_accuracy: 0.9484 - lr: 4.0000e-04\n",
      "Epoch 62/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0363 - accuracy: 0.9871 - val_loss: 0.2079 - val_accuracy: 0.9425 - lr: 4.0000e-04\n",
      "Epoch 63/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0368 - accuracy: 0.9891 - val_loss: 0.2256 - val_accuracy: 0.9325 - lr: 4.0000e-04\n",
      "Epoch 64/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.2370 - val_accuracy: 0.9405 - lr: 4.0000e-04\n",
      "Epoch 65/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.1988 - val_accuracy: 0.9405 - lr: 4.0000e-04\n",
      "Epoch 66/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0327 - accuracy: 0.9876 - val_loss: 0.2101 - val_accuracy: 0.9444 - lr: 4.0000e-04\n",
      "Epoch 67/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0411 - accuracy: 0.9826 - val_loss: 0.1916 - val_accuracy: 0.9484 - lr: 4.0000e-04\n",
      "Epoch 68/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.2067 - val_accuracy: 0.9484 - lr: 4.0000e-04\n",
      "Epoch 69/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.2031 - val_accuracy: 0.9484 - lr: 1.6000e-04\n",
      "Epoch 70/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.2037 - val_accuracy: 0.9484 - lr: 1.6000e-04\n",
      "Epoch 71/75\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.2003 - val_accuracy: 0.9444 - lr: 1.6000e-04\n",
      "Epoch 72/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0348 - accuracy: 0.9866 - val_loss: 0.2109 - val_accuracy: 0.9524 - lr: 1.6000e-04\n",
      "Epoch 73/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.2137 - val_accuracy: 0.9444 - lr: 1.6000e-04\n",
      "Epoch 74/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.1927 - val_accuracy: 0.9504 - lr: 1.6000e-04\n",
      "Epoch 75/75\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.0246 - accuracy: 0.9901 - val_loss: 0.1937 - val_accuracy: 0.9504 - lr: 6.4000e-05\n"
     ]
    }
   ],
   "source": [
    "history = total_model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_data=(x_test, y_test), callbacks=[rlrp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "683e39d7-fb4e-4c17-9e95-02de1ca51cd5",
    "_uuid": "dff9b1bf-1325-4ba2-936a-78cca34c36fb",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:29:22.462463Z",
     "iopub.status.busy": "2022-04-25T19:29:22.461420Z",
     "iopub.status.idle": "2022-04-25T19:36:08.691662Z",
     "shell.execute_reply": "2022-04-25T19:36:08.690817Z",
     "shell.execute_reply.started": "2022-04-25T18:35:39.262167Z"
    },
    "papermill": {
     "duration": 409.769181,
     "end_time": "2022-04-25T19:36:08.691795",
     "exception": false,
     "start_time": "2022-04-25T19:29:18.922614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# female_history = female_model.fit(x_trainF, y_trainF, batch_size=batch_size, epochs=n_epochs, validation_data=(x_testF, y_testF), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "f731dbe4-7c4e-4dce-9d53-1acfdaa2b024",
    "_uuid": "bf5377cb-11fe-458a-888e-dc9bdbcd2784",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:36:19.850901Z",
     "iopub.status.busy": "2022-04-25T19:36:19.849706Z",
     "iopub.status.idle": "2022-04-25T19:41:16.274623Z",
     "shell.execute_reply": "2022-04-25T19:41:16.273655Z",
     "shell.execute_reply.started": "2022-04-25T18:44:19.565417Z"
    },
    "papermill": {
     "duration": 302.122928,
     "end_time": "2022-04-25T19:41:16.274736",
     "exception": false,
     "start_time": "2022-04-25T19:36:14.151808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# male_history = male_model.fit(x_trainM, y_trainM, batch_size=batch_size, epochs=n_epochs, validation_data=(x_testM, y_testM), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.645827,
     "end_time": "2022-04-25T19:41:30.826324",
     "exception": false,
     "start_time": "2022-04-25T19:41:23.180497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Uncomment the code below to see the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:41:44.716704Z",
     "iopub.status.busy": "2022-04-25T19:41:44.715956Z",
     "iopub.status.idle": "2022-04-25T19:41:44.719503Z",
     "shell.execute_reply": "2022-04-25T19:41:44.719038Z",
     "shell.execute_reply.started": "2022-04-25T18:50:41.189795Z"
    },
    "papermill": {
     "duration": 6.779619,
     "end_time": "2022-04-25T19:41:44.719602",
     "exception": false,
     "start_time": "2022-04-25T19:41:37.939983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras import backend as K\\n\\nlayer_name = 'conv1d_11'\\nintermediate_layer_model = keras.Model(inputs=female_model.input,\\n                                       outputs=female_model.get_layer(layer_name).output)\\nintermediate_output = intermediate_layer_model(x_testF)\\nprint(intermediate_output[1,0])\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras import backend as K\n",
    "\n",
    "layer_name = 'conv1d_11'\n",
    "intermediate_layer_model = keras.Model(inputs=female_model.input,\n",
    "                                       outputs=female_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model(x_testF)\n",
    "print(intermediate_output[1,0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dfe9a30b-84ad-4628-a18b-c3db6af78163",
    "_uuid": "2b58f999-e771-492f-b28a-ca7d010f73ab",
    "papermill": {
     "duration": 7.262581,
     "end_time": "2022-04-25T19:41:59.106172",
     "exception": false,
     "start_time": "2022-04-25T19:41:51.843591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Performance Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:42:13.728943Z",
     "iopub.status.busy": "2022-04-25T19:42:13.727844Z",
     "iopub.status.idle": "2022-04-25T19:42:18.734319Z",
     "shell.execute_reply": "2022-04-25T19:42:18.733855Z",
     "shell.execute_reply.started": "2022-04-25T18:50:41.200666Z"
    },
    "papermill": {
     "duration": 12.144273,
     "end_time": "2022-04-25T19:42:18.734429",
     "exception": false,
     "start_time": "2022-04-25T19:42:06.590156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed-gender emotions training Accuracy: 100.00%\n",
      "Mixed-gender emotions testing Accuracy: 95.04%\n"
     ]
    }
   ],
   "source": [
    "# genderless\n",
    "score = total_model.evaluate(x_train,y_train, verbose = 0)\n",
    "print(\"Mixed-gender emotions training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "score = total_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Mixed-gender emotions testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3be869d-46c0-4d0b-b093-6ada4af95417",
    "_uuid": "2ed7d9cb-4602-4f7a-80d2-05cab4d6abb4",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:42:33.029091Z",
     "iopub.status.busy": "2022-04-25T19:42:33.028027Z",
     "iopub.status.idle": "2022-04-25T19:42:36.067622Z",
     "shell.execute_reply": "2022-04-25T19:42:36.066947Z",
     "shell.execute_reply.started": "2022-04-25T18:50:47.928529Z"
    },
    "papermill": {
     "duration": 10.203761,
     "end_time": "2022-04-25T19:42:36.067764",
     "exception": false,
     "start_time": "2022-04-25T19:42:25.864003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score = female_model.evaluate(x_trainF,y_trainF, verbose = 0)\n",
    "# print(\"Female emotions training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "# score = female_model.evaluate(x_testF, y_testF, verbose=0)\n",
    "# print(\"Female emotions testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2efe6f55-a21c-4ae1-8c2f-eda2c9564469",
    "_uuid": "5b0462f9-1f5b-4908-a3f0-315477dd0176",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:42:50.302526Z",
     "iopub.status.busy": "2022-04-25T19:42:50.301541Z",
     "iopub.status.idle": "2022-04-25T19:42:52.386313Z",
     "shell.execute_reply": "2022-04-25T19:42:52.387516Z",
     "shell.execute_reply.started": "2022-04-25T18:50:51.532293Z"
    },
    "papermill": {
     "duration": 8.936619,
     "end_time": "2022-04-25T19:42:52.387691",
     "exception": false,
     "start_time": "2022-04-25T19:42:43.451072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score = male_model.evaluate(x_trainM,y_trainM, verbose = 0)\n",
    "# print(\"Male emotions training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "# score = male_model.evaluate(x_testM, y_testM, verbose=0)\n",
    "# print(\"Male emotions testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ae8241f-ac42-4312-ad18-2643b39f2ae8",
    "_uuid": "221e07a6-f3cb-41fb-a2c4-52536a15b8c7",
    "papermill": {
     "duration": 7.101603,
     "end_time": "2022-04-25T19:43:06.575444",
     "exception": false,
     "start_time": "2022-04-25T19:42:59.473841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Validation trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:43:21.063939Z",
     "iopub.status.busy": "2022-04-25T19:43:21.062952Z",
     "iopub.status.idle": "2022-04-25T19:43:21.400524Z",
     "shell.execute_reply": "2022-04-25T19:43:21.400957Z",
     "shell.execute_reply.started": "2022-04-25T18:50:54.220275Z"
    },
    "papermill": {
     "duration": 7.410908,
     "end_time": "2022-04-25T19:43:21.401079",
     "exception": false,
     "start_time": "2022-04-25T19:43:13.990171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_graphs(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16efab44-61a0-4393-87e6-e8d379f853d7",
    "_uuid": "be327c88-e087-4eb8-a928-a29c60f8633d",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:43:35.585358Z",
     "iopub.status.busy": "2022-04-25T19:43:35.584333Z",
     "iopub.status.idle": "2022-04-25T19:43:35.914056Z",
     "shell.execute_reply": "2022-04-25T19:43:35.914494Z",
     "shell.execute_reply.started": "2022-04-25T18:50:54.662842Z"
    },
    "papermill": {
     "duration": 7.192846,
     "end_time": "2022-04-25T19:43:35.914620",
     "exception": false,
     "start_time": "2022-04-25T19:43:28.721774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_graphs(female_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26b8f452-bce7-422f-a988-16de7685da76",
    "_uuid": "72f72742-ccc6-480a-88f0-97f8477639fb",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:43:50.692501Z",
     "iopub.status.busy": "2022-04-25T19:43:50.691108Z",
     "iopub.status.idle": "2022-04-25T19:43:51.015556Z",
     "shell.execute_reply": "2022-04-25T19:43:51.016161Z",
     "shell.execute_reply.started": "2022-04-25T18:50:55.086098Z"
    },
    "papermill": {
     "duration": 7.456026,
     "end_time": "2022-04-25T19:43:51.016319",
     "exception": false,
     "start_time": "2022-04-25T19:43:43.560293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_graphs(male_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ce5b7034-fbdc-4ba5-be4f-ca91023e53bf",
    "_uuid": "aaa74df4-a2dd-460a-85d1-93dede24d13c",
    "papermill": {
     "duration": 7.083658,
     "end_time": "2022-04-25T19:44:05.029840",
     "exception": false,
     "start_time": "2022-04-25T19:43:57.946182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# predicting on test data.\n",
    "pred_test = total_model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "y_test_ = encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_, y_pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix for Female Emotions', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4984e605-6e49-460c-a9e1-4042abc00f78",
    "_uuid": "26fea659-f7ad-47eb-8e04-119ff1169329",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:44:19.581489Z",
     "iopub.status.busy": "2022-04-25T19:44:19.580396Z",
     "iopub.status.idle": "2022-04-25T19:44:20.039975Z",
     "shell.execute_reply": "2022-04-25T19:44:20.038846Z",
     "shell.execute_reply.started": "2022-04-25T18:50:55.521077Z"
    },
    "papermill": {
     "duration": 7.811079,
     "end_time": "2022-04-25T19:44:20.040093",
     "exception": false,
     "start_time": "2022-04-25T19:44:12.229014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # predicting on test data.\n",
    "# pred_test = female_model.predict(x_testF)\n",
    "# y_pred = encoder.inverse_transform(pred_test)\n",
    "# y_test_ = encoder.inverse_transform(y_testF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "08b69691-4a7e-4c71-961b-ab16c020eb79",
    "_uuid": "f083eaea-21b0-49a3-bea9-e693e7a77453",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:44:34.637572Z",
     "iopub.status.busy": "2022-04-25T19:44:34.630282Z",
     "iopub.status.idle": "2022-04-25T19:44:35.018025Z",
     "shell.execute_reply": "2022-04-25T19:44:35.018489Z",
     "shell.execute_reply.started": "2022-04-25T18:50:56.130165Z"
    },
    "papermill": {
     "duration": 7.76569,
     "end_time": "2022-04-25T19:44:35.018625",
     "exception": false,
     "start_time": "2022-04-25T19:44:27.252935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test_, y_pred)\n",
    "# plt.figure(figsize = (12, 10))\n",
    "# cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "# sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "# plt.title('Confusion Matrix for Female Emotions', size=20)\n",
    "# plt.xlabel('Predicted Labels', size=14)\n",
    "# plt.ylabel('Actual Labels', size=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "27a1522a-d7f3-40f3-a621-e6aadb093de7",
    "_uuid": "a9afc111-20f1-4a9b-b302-f3fdd0d1e1a7",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:44:49.547600Z",
     "iopub.status.busy": "2022-04-25T19:44:49.546723Z",
     "iopub.status.idle": "2022-04-25T19:44:49.882873Z",
     "shell.execute_reply": "2022-04-25T19:44:49.882354Z",
     "shell.execute_reply.started": "2022-04-25T18:50:56.776274Z"
    },
    "papermill": {
     "duration": 8.000924,
     "end_time": "2022-04-25T19:44:49.882976",
     "exception": false,
     "start_time": "2022-04-25T19:44:41.882052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # predicting on test data.\n",
    "# pred_test = male_model.predict(x_testM)\n",
    "# y_pred = encoder.inverse_transform(pred_test)\n",
    "# y_test_ = encoder.inverse_transform(y_testM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "678e9d91-862a-4159-9877-caa275302c8e",
    "_uuid": "e45908f7-d67f-4442-92cd-11d50f224aa6",
    "execution": {
     "iopub.execute_input": "2022-04-25T19:45:03.974337Z",
     "iopub.status.busy": "2022-04-25T19:45:03.973464Z",
     "iopub.status.idle": "2022-04-25T19:45:04.392019Z",
     "shell.execute_reply": "2022-04-25T19:45:04.393744Z",
     "shell.execute_reply.started": "2022-04-25T18:50:57.445557Z"
    },
    "papermill": {
     "duration": 7.338441,
     "end_time": "2022-04-25T19:45:04.393955",
     "exception": false,
     "start_time": "2022-04-25T19:44:57.055514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test_, y_pred)\n",
    "# plt.figure(figsize = (12, 10))\n",
    "# cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "# sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "# plt.title('Confusion Matrix for Male Emotions', size=20)\n",
    "# plt.xlabel('Predicted Labels', size=14)\n",
    "# plt.ylabel('Actual Labels', size=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_model.save(\"model123.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# # to save encoder \n",
    "# joblib.dump(encoder,'Encoder.joblib',compress=9)\n",
    "\n",
    "# load it when test\n",
    "encoder=joblib.load('Encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scaler.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # to save encoder \n",
    "# joblib.dump(scaler,'Scaler.joblib',compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:7: FutureWarning: Pass rate=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:14: FutureWarning: Pass sr=22050, n_steps=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/qb/17cfgm351wz2s07gx63rcx0w0000gn/T/ipykernel_68762/3565566241.py:17: FutureWarning: Pass rate=1.25 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, speed_factor)\n"
     ]
    }
   ],
   "source": [
    "#sample_rate = 22050\n",
    "\n",
    "def extract_features(data):\n",
    "    \n",
    "    result = np.array([])\n",
    "    \n",
    "    #mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=42) #42 mfcc so we get frames of ~60 ms\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=22050, n_mfcc=58)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    result = np.array(mfccs_processed)\n",
    "     \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=3, offset=0.5, res_type='kaiser_fast') \n",
    "    \n",
    "    #without augmentation\n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    #noised\n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "    \n",
    "    #stretched\n",
    "    stretch_data = stretch(data)\n",
    "    res3 = extract_features(stretch_data)\n",
    "    result = np.vstack((result, res3))\n",
    "    \n",
    "    #shifted\n",
    "    shift_data = shift(data)\n",
    "    res4 = extract_features(shift_data)\n",
    "    result = np.vstack((result, res4))\n",
    "    \n",
    "    #pitched\n",
    "    pitch_data = pitch(data, sample_rate)\n",
    "    res5 = extract_features(pitch_data)\n",
    "    result = np.vstack((result, res5)) \n",
    "    \n",
    "    #speed up\n",
    "    higher_speed_data = higher_speed(data)\n",
    "    res6 = extract_features(higher_speed_data)\n",
    "    result = np.vstack((result, res6))\n",
    "    \n",
    "    #speed down\n",
    "    lower_speed_data = higher_speed(data)\n",
    "    res7 = extract_features(lower_speed_data)\n",
    "    result = np.vstack((result, res7))\n",
    "    \n",
    "    return result\n",
    "\n",
    "features = get_features('ALL/DC_d09.wav')\n",
    "check = []\n",
    "for elem in features: \n",
    "    check.append(elem)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'disgust'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder=joblib.load('Encoder.joblib')\n",
    "ans = total_model.predict(np.expand_dims(scaler.transform(features),2))\n",
    "ans = ans.sum(axis=0)\n",
    "f = [0,0,0,0,0,0]\n",
    "f[np.argmax(ans)] = 1\n",
    "encoder.inverse_transform([f])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 1701.03556,
   "end_time": "2022-04-25T19:45:12.769055",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-25T19:16:51.733495",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
